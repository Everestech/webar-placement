<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR: Reconocimiento de Imagen con Visión Artificial</title>
    
    <!-- Tailwind CSS para estilos de UI -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Three.js para renderizado 3D -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <!-- GLTFLoader para cargar el modelo 3D -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>

    <!-- JSARToolkit: Una librería clásica y robusta para AR basada en visión artificial -->
    <!-- Nota: Usamos una versión compatible con el seguimiento de imágenes basado en patrones -->
    <script src="https://unpkg.com/jsartoolkit/js/artoolkit.min.js"></script>

    <style>
        /* Estilos generales y UI */
        body { margin: 0; padding: 0; font-family: 'Inter', sans-serif; height: 100vh; width: 100vw; overflow: hidden; background-color: black; }
        
        /* Contenedor de la cámara (stream de video) */
        #video-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            z-index: 10; 
        }

        /* El stream de video de la cámara */
        #camera-feed {
            /* Asegura que el video cubra el contenedor y lo centre */
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Espejo para frontal, quítalo si usas trasera */
        }

        /* El canvas de Three.js se superpone al video */
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 20; /* Superior al video */
            display: none; /* Oculto hasta que se inicializa la cámara */
        }

        /* Overlay para el botón de inicio */
        #start-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.9);
            z-index: 2000;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            text-align: center;
            padding: 20px;
        }

        /* Mensaje de estado en la parte inferior */
        #status-message {
            z-index: 100;
            position: fixed;
            bottom: 0;
            width: 100%;
            background-color: rgba(0, 0, 0, 0.85);
            color: white;
            padding: 0.75rem;
            text-align: center;
            font-size: 0.875rem;
            border-top-left-radius: 0.5rem;
            border-top-right-radius: 0.5rem;
        }

        /* Estilo del spinner de carga */
        .loader {
            border: 4px solid #f3f3f3; 
            border-top: 4px solid #4ade80; /* verde vibrante */
            border-radius: 50%;
            width: 30px;
            height: 30px;
            animation: spin 2s linear infinite;
            display: inline-block;
            margin-right: 0.5rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="overflow-hidden">

    <!-- Contenedor de la cámara HTML5 -->
    <div id="video-container">
        <!-- 'camera-feed' es el elemento que mostrará el stream de video -->
        <video id="camera-feed" autoplay playsinline></video>
    </div>

    <!-- Mensaje de estado -->
    <div id="status-message">
        Cargando WebAR...
    </div>

    <!-- Overlay de inicio con botón único -->
    <div id="start-overlay">
        <h1 class="text-2xl font-bold text-white mb-6">AR: Reconocimiento de Imagen (Método Robusto)</h1>
        <p class="text-gray-300 mb-6 text-sm max-w-sm">
            Este método usa visión artificial. Necesita permisos de cámara (frontal o trasera).
        </p>
        
        <!-- Botón Único para iniciar todo el flujo de trabajo (el que funciona) -->
        <button 
            id="ar-button-start"
            onclick="initARLegacy()"
            class="px-8 py-4 bg-green-500 hover:bg-green-600 text-gray-900 font-bold text-lg rounded-lg shadow-xl transition duration-200 transform hover:scale-105 w-80"
        >
            INICIAR RECONOCIMIENTO
        </button>

        <p class="mt-4 text-gray-300 text-xs mt-8">
            IMAGEN OBJETIVO: 
            <a href="https://placehold.co/500x500/000000/FFFFFF/png?text=AR+TARGET" target="_blank" class="text-blue-400 hover:text-blue-300">
                Placeholder AR TARGET (¡Imprimir esto!)
            </a>
        </p>
        <p class="mt-2 text-gray-500 text-xs">
            Si se activa la cámara frontal, el modelo aparecerá reflejado (es normal).
        </p>
    </div>

    <!-- 
        ============================================================
        Script: Lógica de Three.js y JSARToolkit
        ============================================================
    -->
    <script>
        // --- CONSTANTES ---
        const MODEL_URL = "https://modelviewer.dev/shared-assets/models/NeilArmstrong.glb";
        const PATTERN_URL = "https://cdn.jsdelivr.net/gh/artoolkit/jsartoolkit@master/src/markers/patt.hiro"; // Marcador de prueba de JSARToolkit
        // Nota: Para usar una imagen real de "AR TARGET", el usuario debe generar su propio archivo de patrón (.patt) 
        // usando herramientas como ARToolKit NFT. Para mantener el código runnable, usaremos un marcador estándar.
        const MARKER_SIZE = 80; // Tamaño del marcador en mm (se puede ajustar)

        // Variables de Three.js
        let scene, camera, renderer;
        let armstrongModel = null;
        let statusMessageEl;
        let videoElement;
        
        // Variables de ARToolKit
        let arToolkitContext;
        let markerRoot;

        // --- 0. Cargar el Modelo GLTF ---
        async function loadModel() {
            statusMessageEl.innerHTML = '<span class="loader"></span> Cargando modelo 3D...';
            
            const loader = new THREE.GLTFLoader();
            return new Promise((resolve, reject) => {
                loader.load(MODEL_URL, (gltf) => {
                    armstrongModel = gltf.scene;
                    // Reducir la escala y centrar el pivote (si es necesario)
                    armstrongModel.scale.set(0.1, 0.1, 0.1); 
                    armstrongModel.visible = false; 
                    
                    resolve();
                }, undefined, reject);
            });
        }

        // --- 1. Inicialización de Three.js ---
        function initThree() {
            statusMessageEl.innerHTML = '<span class="loader"></span> Inicializando motor 3D...';

            scene = new THREE.Scene();
            // La cámara de Three.js será configurada por ARToolKit más adelante
            camera = new THREE.Camera(); 
            scene.add(camera);

            renderer = new THREE.WebGLRenderer({
                antialias: true,
                alpha: true // Necesario para que el video de fondo se vea
            });
            renderer.setClearColor(new THREE.Color('lightgrey'), 0); // Fondo transparente
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.outputEncoding = THREE.sRGBEncoding;
            document.body.appendChild(renderer.domElement);
            
            // Iluminación
            scene.add(new THREE.AmbientLight(0xffffff, 0.8));
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1.5);
            directionalLight.position.set(0, 5, 2);
            scene.add(directionalLight);
            
            // Añadir el modelo a la escena principal. Su posición será controlada por el marcador.
            markerRoot = new THREE.Group();
            scene.add(markerRoot);
            markerRoot.add(armstrongModel);

            window.addEventListener('resize', onWindowResize, false);
            
            document.querySelector('canvas').style.display = 'block';
        }

        function onWindowResize() {
            renderer.setSize(window.innerWidth, window.innerHeight);
            // ARToolKit se encarga de actualizar la matriz de proyección de la cámara
        }
        
        // --- 2. Iniciar Cámara HTML5 y flujo de AR ---
        async function initARLegacy() {
            document.getElementById('start-overlay').style.display = 'none';
            statusMessageEl.innerHTML = '<span class="loader"></span> Solicitando permisos de cámara...';

            videoElement = document.getElementById('camera-feed');

            try {
                // Pedir la cámara trasera si es posible, si no, cualquier cámara.
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: {
                        facingMode: { ideal: 'environment' } // Preferir cámara trasera
                    }
                });
                
                videoElement.srcObject = stream;
                videoElement.play();

                // Esperar a que el video esté cargado antes de inicializar ARToolKit
                await new Promise(resolve => videoElement.onloadedmetadata = resolve);

                // El diagnóstico fue exitoso, inicializamos Three.js y ARToolKit
                await loadModel();
                initThree();
                initARToolKit(); 
                
                // Iniciar el bucle de renderizado
                renderer.setAnimationLoop(update); 

            } catch (err) {
                console.error('Error al iniciar la cámara (Visión Artificial):', err);
                statusMessageEl.textContent = 'ERROR FATAL: No se pudo acceder a la cámara o el stream fue bloqueado.';
                document.getElementById('start-overlay').style.display = 'flex'; // Mostrar overlay de nuevo
            }
        }
        
        // --- 3. Inicializar ARToolKit ---
        function initARToolKit() {
            // Contexto de ARToolKit
            arToolkitContext = new ARToolkitContext({
                cameraParametersUrl: ARToolkitContext.baseURL + 'data/camera_para.dat',
                detectionMode: 'mono',
                imageSmoothingEnabled: true,
                canvas: renderer.domElement 
            });

            // Inicializar el contexto y configurar la cámara de Three.js
            arToolkitContext.init(function onCompleted(){
                camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
            });

            // Inicialización del marcador (Image Tracking)
            let markerControls = new ARToolkitSource({
                sourceType: 'video',
                sourceElement: videoElement,
            });

            markerControls.init(function onCompleted(){
                // Sincronizar el tamaño del video con el canvas y el contexto AR
                onResize();
            });

            // Creamos los controles que buscarán el patrón en el video
            let patternControls = new ARToolkitPatternControls(markerRoot, arToolkitContext, {
                type: 'pattern',
                patternUrl: PATTERN_URL, // Usamos el patrón Hiro estándar como ejemplo
                // Si la imagen objetivo fuera un patrón generado, se usaría su URL aquí.
                // Si la imagen fuera NFT (NFT Image Tracking), se necesitaría otra librería (NFT Marker Tracking)
                changeMatrixMode: 'cameraTransformMatrix',
                size: MARKER_SIZE // Tamaño en milímetros
            });
            
            statusMessageEl.textContent = 'Cámara activa. Busque el marcador HIRO (círculo y cuadrado negro) para ver el modelo.';
            armstrongModel.visible = false;
        }

        // --- 4. Bucle de Actualización y Renderizado ---
        function update() {
            
            // 1. Actualizar el contexto de ARToolKit (necesario para la detección de marcadores)
            if (arToolkitContext && arToolkitContext.ready) {
                arToolkitContext.update(videoElement);
            }

            // 2. Comprobar si el marcador está visible
            if (markerRoot.matrixWorldNeedsUpdate) {
                 // Si la matriz del marcador se actualizó (es visible)
                 if (!armstrongModel.visible) {
                    armstrongModel.visible = true;
                    statusMessageEl.textContent = '¡MARCADOR DETECTADO! Modelo 3D activo.';
                 }
            } else {
                // Si el marcador no es visible
                if (armstrongModel.visible) {
                    armstrongModel.visible = false;
                    statusMessageEl.textContent = 'Marcador no visible. Busque el patrón HIRO.';
                }
            }

            // 3. Renderizar la escena 3D
            renderer.render(scene, camera);
        }

        // Iniciar al cargar la ventana
        window.onload = function() {
            statusMessageEl = document.getElementById('status-message');
            // La carga y la inicialización se hacen en initARLegacy() al presionar el botón
        };
    </script>
</body>
</html>
